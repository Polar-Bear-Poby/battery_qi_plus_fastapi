import torch
import os
from ai.ai_model.deeplab import DeepLab

# âœ… ëª¨ë¸ ìºì‹± (í•œ ë²ˆë§Œ ë¡œë“œ)
_model = None
_device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def get_model():
    """
    ğŸ“Œ AI ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ê³ , ì´í›„ì—ëŠ” ìºì‹±ëœ ëª¨ë¸ì„ ì‚¬ìš©
    """
    global _model

    if _model is None:
        model_path = r"D:\2025_1\battery_qi_fastapi\ai\weights\battery_rgb.pt"  # âœ… ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ ì§€ì •
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"âŒ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")

        print("ğŸš€ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        _model = DeepLab(num_classes=4, backbone="drn", sync_bn=False, freeze_bn=False)
        checkpoint = torch.load(model_path, map_location=_device, weights_only=False)  # âœ… CPU ë˜ëŠ” GPU í™˜ê²½ ìë™ ì ìš©
        _model.load_state_dict(checkpoint['state_dict'])
        _model.to(_device)
        _model.eval()
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    return _model

def unload_model():
    """
    ğŸ“Œ AI ëª¨ë¸ ì–¸ë¡œë“œ (ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œ)
    - C#ì—ì„œ shutdown ëª…ë ¹ì´ ë“¤ì–´ì™”ì„ ë•Œ ì‚¬ìš© ê°€ëŠ¥
    """
    global _model

    if _model is not None:
        print("ğŸ”„ ëª¨ë¸ ì–¸ë¡œë“œ ì¤‘...")
        del _model
        _model = None
        torch.cuda.empty_cache()  # âœ… GPU ìºì‹œ ì •ë¦¬ (GPU ì‚¬ìš© ì‹œ)
        print("âœ… ëª¨ë¸ ì–¸ë¡œë“œ ì™„ë£Œ!")
